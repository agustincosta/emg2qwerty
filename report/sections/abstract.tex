\begin{abstract}
This paper presents enhancements to the EMG2QWERTY framework for predicting keyboard typing from surface electromyography (sEMG) signals. We introduce two key innovations: (1) an autoencoder-based dimensionality reduction technique that compresses 32-channel EMG spectrograms to a 16-channel bottleneck representation while preserving essential information, and (2) a multi-scale temporal depth-separable (TDS) convolutional architecture that captures dependencies at multiple time scales simultaneously. Our approach addresses the challenges of high-dimensional, noisy sEMG signals and the complex temporal patterns in typing movements. Experiments on the EMG2QWERTY dataset demonstrate that our proposed modifications improve character error rate (CER) compared to the baseline model while reducing model complexity. The results suggest that combining dimensionality reduction with multi-scale temporal modeling is a promising approach for EMG-based typing interfaces, with potential applications in assistive technology and human-computer interaction.
\end{abstract} 