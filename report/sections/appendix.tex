\section{Code repository}
The code for this project is available at \url{https://github.com/agustincosta/emg2qwerty}

\section{Implementation Details}

\subsection{Autoencoder Reconstruction}
\begin{figure}[h]
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[height=7cm,width=\textwidth]{../output/spectrogram_comparison_0_reduced.png}
        \caption{Visualization of original and reconstructed spectrograms for 16 channels of a random data sample}
        \label{fig:autoencoder_reconstruction}
    \end{minipage}
    \hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[height=7cm, width=0.8\textwidth]{../output/reconstruction_error_0_reduced.png}
        \caption{Visualization of the reconstruction error for the same random data sample}
        \label{fig:autoencoder_error}
    \end{minipage}
\end{figure}


\subsection{Multi-Scale TDS Convolution Block}

The detailed implementation of the MultiScaleTDSConv2dBlock shown in Algorithm \ref{alg:multi_scale_tds_conv2d_block}:

\begin{algorithm}[h]
    \caption{MultiScaleTDSConv2dBlock Forward Pass}
    \begin{algorithmic}[1]
        \STATE \textbf{Input:} x (input tensor), channels, width, kernel\_widths=[$k_1$, $k_2$, $k_3$]
        \STATE \textbf{Output:} y (output tensor)
        \STATE // Reshape for 2D convolutions: TNC -> NCHW
        \STATE x\_reshaped = Reshape(x) to (N, channels, width, T)
        \STATE // Apply multi-scale convolutions in parallel
        \STATE features\_1 = Conv2d(x\_reshaped, channels, kernel\_size=(1, $k_1$))
        \STATE features\_2 = Conv2d(x\_reshaped, channels, kernel\_size=(1, $k_2$))
        \STATE features\_3 = Conv2d(x\_reshaped, channels, kernel\_size=(1, $k_3$))
        \STATE // Find minimum time dimension among all features
        \STATE min\_time = Min(features\_1.shape[3], features\_2.shape[3], features\_3.shape[3])
        \STATE // Trim all features to the minimum time dimension
        \STATE features\_1 = features\_1[..., :min\_time]
        \STATE features\_2 = features\_2[..., :min\_time]
        \STATE features\_3 = features\_3[..., :min\_time]
        \STATE // Concatenate along the channel dimension
        \STATE x\_concat = Concatenate([features\_1, features\_2, features\_3], dim=1)
        \STATE // Merge features using 1Ã—1 convolution
        \STATE x\_merged = Conv2d(x\_concat, channels, kernel\_size=1)
        \STATE x\_merged = ReLU(x\_merged)
        \STATE // Reshape back: NCHW -> TNC
        \STATE x\_out = Reshape(x\_merged) to (T\_out, N, channels * width)
        \STATE // Add residual connection
        \STATE residual = x[-T\_out:]
        \STATE y = x\_out + residual
        \STATE // Apply layer normalization
        \STATE y = LayerNorm(y)
        \STATE \textbf{return} y
    \end{algorithmic}
    \label{alg:multi_scale_tds_conv2d_block}
\end{algorithm}

\subsection{Training Hyperparameters}

The hyperparameters used for training the autoencoder and the main model are shown in Table \ref{tab:training_hyperparameters}:

\begin{table}[h]
    \centering
    \caption{Training Hyperparameters}
    \begin{tabular}{lll}
        \toprule
        Hyperparameter          & Autoencoder & Main Model      \\
        \midrule
        Optimizer               & Adam        & Adam            \\
        Learning rate           & 1e-3        & 1e-3            \\
        Batch size              & 32          & 32              \\
        Training epochs         & 150         & 150             \\
        Early stopping patience & 10          & 10              \\
        Learning rate scheduler & None        & CosineAnnealing \\
        \bottomrule
    \end{tabular}
    \label{tab:training_hyperparameters}
\end{table}

\section{Additional Results}

\subsection{Learning Curves}

\subsubsection{Autoencoder}
\begin{figure}[H]
    \centering
    \includegraphics[height=7cm,width=0.6\textwidth]{../results/autoencoder-new/loss_plot.png}
    \caption{Learning curves showing training and validation loss for the autoencoder}
    \label{fig:autoencoder_loss}
\end{figure}

\subsubsection{Baseline Model}
\begin{figure}[H]
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[height=7cm,width=\textwidth]{../results/model-tiny-new/loss_plot.png}
        \caption{Learning curves showing training and validation loss for the baseline model}
        \label{fig:baseline_loss}
    \end{minipage}
    \hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[height=7cm, width=\textwidth]{../results/model-tiny-new/cer_zoomed_plot.png}
        \caption{Learning curves showing training and validation CER for the baseline model}
        \label{fig:baseline_cer}
    \end{minipage}
\end{figure}

\subsubsection{Autoencoder Only Model}
\begin{figure}[H]
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[height=7cm,width=\textwidth]{../results/model-autoencoder-tiny-new/loss_plot.png}
        \caption{Learning curves showing training and validation loss for the autoencoder only model}
        \label{fig:autoencoder_only_loss}
    \end{minipage}
    \hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[height=7cm, width=\textwidth]{../results/model-autoencoder-tiny-new/cer_zoomed_plot.png}
        \caption{Learning curves showing training and validation CER for the autoencoder only model}
        \label{fig:autoencoder_only_cer}
    \end{minipage}
\end{figure}

\subsubsection{Multi-Scale TDS Convolution Model}
\begin{figure}[H]
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[height=7cm,width=\textwidth]{../results/model-multi-scale-tiny/loss_plot.png}
        \caption{Learning curves showing training and validation loss for the multi-scale TDS convolution model}
        \label{fig:multi_scale_loss}
    \end{minipage}
    \hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[height=7cm, width=\textwidth]{../results/model-multi-scale-tiny/cer_zoomed_plot.png}
        \caption{Learning curves showing training and validation CER for the multi-scale TDS convolution model}
        \label{fig:multi_scale_cer}
    \end{minipage}
\end{figure}

\subsubsection{Autoencoder and Multi-Scale TDS Convolution Model}
\begin{figure}[H]
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[height=7cm,width=\textwidth]{../results/model-multi-scale-autoencoder-tiny/loss_plot.png}
        \caption{Learning curves showing training and validation loss for the autoencoder and multi-scale TDS convolution block}
        \label{fig:autoencoder_multi_scale_loss}
    \end{minipage}
    \hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[height=7cm, width=\textwidth]{../results/model-multi-scale-autoencoder-tiny/cer_zoomed_plot.png}
        \caption{Learning curves showing training and validation CER for the autoencoder and multi-scale TDS convolution block}
        \label{fig:autoencoder_multi_scale_cer}
    \end{minipage}
\end{figure}
